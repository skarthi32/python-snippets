 columns = ["vb_account_seq", "start_time"]

    df = spark.createDataFrame(data=data, schema=columns)

    orderByCols = [col("vb_account_seq"), col("start_time").desc()]

    row_number_window = Window.orderBy(*orderByCols)

    df = df.withColumn("prev_start_date", lag("start_time", 1).over(row_number_window))

    df = df.withColumn("prev_start_date_order", row_number().over(row_number_window))

    first_last_row_window = Window.partitionBy(col('vb_account_seq')).orderBy(*orderByCols).rowsBetween(
        Window.unboundedPreceding,
        Window.unboundedFollowing)
    df = df.withColumn("prev_start_date_first_row", first("prev_start_date_order").over(first_last_row_window))

    df = df.withColumn("first_vb_account_seq", col("prev_start_date_order") == col("prev_start_date_first_row"))

    df = df.withColumn("prev_start_date",
                       when(col("first_vb_account_seq") == True, None).otherwise(col("prev_start_date")))

    df = df.withColumn("end_date", col("prev_start_date") - lit(1))

    df.show(truncate=False)
